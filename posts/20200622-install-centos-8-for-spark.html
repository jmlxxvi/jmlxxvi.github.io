<article>
    <p>Posted on Monday 22 June 2020 </p>
    <div class="article_title">
        <h3>Installing Spark 3 on CEntOS 8</h3>
    </div>



    <div class="article_text">

        <p>
            If you want to start researching, learning or even creating 
            a <a class="reference external" href="https://en.wikipedia.org/wiki/Proof_of_concept" target="_blank">POC</a>
            for Spark applications here are the steps to install it on CEntOS 8 for that purpose.
        </p>

        <p>
            <i>Disclaimer:</i> Steps here are for development purposes as we are not concerning about security (almost) at all. 
            <br>
            Being said that, let's begin.
            <br>
            I'm using the minimal version of this OS as this is all I need. If you want to use the complete version, that's fine, 
            it will fork fine too. 
            Just go to <a class="reference external" href="https://www.centos.org/download/">https://www.centos.org/download/</a>
            <br>
            In order to get the minimal version (not so minimal these days I have to confess) go to 
            <a class="reference external" href="http://isoredirect.centos.org/centos/8/isos/x86_64">http://isoredirect.centos.org/centos/8/isos/x86_64</a>, 
            pick a mirror and get the file <span class="monospaced">CentOS-8.2.2004-x86_64-minimal.iso</span>
            <br>
            If you are getting here from the future the last version available for download might be newer and most likely will work fine. 
            I can't tell because I'm here in the present.
            <br>
            You can use tha ISO image to install the OS on any machine you want<sup><a href="#p1">[1]</a></sup>, 
            something we are not taking care here but you may want to check
            <a href="https://linoxide.com/distros/how-to-install-centos/" target="_blank">there</a>
        </p>

        <p>
            Once you have the OS intalled we are ready to set it up. 
            <br>
            I didn't tell you (sorry) but it would be great if you had created a user for Spark during installation.
            <br>
            If you didn't it's OK, just:
        </p>

        <pre><code class="shell">[root@sp3m ~]# useradd data
[root@sp3m ~]# passwd data
Changing password for user data.
New password: 
BAD PASSWORD: The password is shorter than 8 characters
Retype new password: 
passwd: all authentication tokens updated successfully.
[root@sp3m ~]# usermod -aG wheel data</code></pre>

        <p>
            Here we created the user <span class="monospaced">data</span>, changed his password and finally we included him to 
            the <span class="monospaced">wheel</span> group to make him able to <span class="monospaced">sudo</span>. 
            <br>
            I am feelling bold today and used <span class="monospaced">root</span> but you may want to use any regular user 
            with <span class="monospaced">sudo</span> privileges.
        </p>
        <p>
            I hope you forgive me if you are a Security Analist or something like that. Next we are doing a couple of things not
            considered among the best security practices but we are creating a development/training box here (are we?)
        </p>

        <pre><code class="shell">[root@sp3m ~]# sudo systemctl stop firewalld
[root@sp3m ~]# sudo systemctl disable firewalld
Removed /etc/systemd/system/multi-user.target.wants/firewalld.service.
Removed /etc/systemd/system/dbus-org.fedoraproject.FirewallD1.service.</code></pre>

        <p>
            After that edit the file <span class="monospaced">/etc/selinux/config</span> and change
            <br>
            <span class="monospaced">SELINUX=enforcing</span>
            to
            <span class="monospaced">SELINUX=disabled</span>
        </p>

        <p>
            You may want to upgrade the system although this is not estrictly necessary: 
        </p>

        <pre><code class="shell">[root@sp3m ~]# yum upgrade
CentOS-8 - AppStream          3.4 MB/s | 5.8 MB     00:01    
CentOS-8 - Base               2.7 MB/s | 2.2 MB     00:00    
CentOS-8 - Extras              11 kB/s | 6.7 kB     00:00    
Dependencies resolved.
===============================================================================
Package           Architecture Version                   Repository     Size
===============================================================================
Installing:
kernel                  x86_64 4.18.0-193.6.3.el8_2          BaseOS    2.8 M
kernel-core             x86_64 4.18.0-193.6.3.el8_2          BaseOS     28 M
kernel-modules          x86_64 4.18.0-193.6.3.el8_2          BaseOS     23 M
Upgrading:
bpftool                 x86_64 4.18.0-193.6.3.el8_2          BaseOS    3.4 M
coreutils               x86_64 8.30-7.el8_2.1                BaseOS    1.2 M
coreutils-common        x86_64 8.30-7.el8_2.1                BaseOS    2.0 M
gnutls                  x86_64 3.6.8-10.el8_2                BaseOS    915 k
initscripts             x86_64 10.00.6-1.el8_2.1             BaseOS    338 k
kernel-tools            x86_64 4.18.0-193.6.3.el8_2          BaseOS    2.9 M
kernel-tools-libs       x86_64 4.18.0-193.6.3.el8_2          BaseOS    2.8 M
microcode_ctl           x86_64 4:20191115-4.20200602.2.el8_2 BaseOS    2.6 M
python3-perf            x86_64 4.18.0-193.6.3.el8_2          BaseOS    2.9 M
python3-syspurpose      x86_64 1.26.17-1.el8_2               BaseOS    286 k
selinux-policy          noarch 3.14.3-41.el8_2.4             BaseOS    614 k
selinux-policy-targeted noarch 3.14.3-41.el8_2.4             BaseOS     15 M
sos                     noarch 3.8-6.el8_2                   BaseOS    522 k
systemd                 x86_64 239-30.el8_2                  BaseOS    3.5 M
systemd-libs            x86_64 239-30.el8_2                  BaseOS    1.1 M
systemd-pam             x86_64 239-30.el8_2                  BaseOS    449 k
systemd-udev            x86_64 239-30.el8_2                  BaseOS    1.3 M
tzdata                  noarch 2020a-1.el8                   BaseOS    469 k
Installing dependencies:
xkeyboard-config        noarch 2.28-1.el8                    AppStream 782 k
Installing weak dependencies:
libxkbcommon            x86_64 0.9.1-1.el8                   AppStream 116 k

Transaction Summary
===============================================================================
Install   5 Packages
Upgrade  18 Packages

Total download size: 97 M
Is this ok [y/N]: y</code></pre>

        <p>
            After the <span class="monospaced">selinux</span> change and (maybe) the upgrade, reboot the computer: 
        </p>

        <pre><code class="shell">[root@sp3m ~]# reboot</code></pre>

        <p>
            Install some packages we need: 
        </p>

        <pre><code class="shell">[root@sp3m ~]# yum install wget curl net-tools tar
Last metadata expiration check: 0:26:17 ago on lun 22 jun 2020 20:58:01 EDT.
Package curl-7.61.1-12.el8.x86_64 is already installed.
Package net-tools-2.0-0.51.20160912git.el8.x86_64 is already installed.
Package tar-2:1.30-4.el8.x86_64 is already installed.
Dependencies resolved.
=============================================================
    Package  Architecture  Version          Repository  Size
=============================================================
Installing:
    wget     x86_64        1.19.5-8.el8_1.1 AppStream   735 k

Transaction Summary
=============================================================
Install  1 Package

Total download size: 735 k
Installed size: 2.9 M
Is this ok [y/N]: y</code></pre>

        <p>
            One last installation, Java. Spark 3 is compatible with Java 11 so we are installing that.
        </p>

        <pre><code class="shell">yum install java-11-openjdk java-11-openjdk-devel</code></pre>

        <p>
            Now we are ready to install and setup Spark.
            <br>
            Please note that from now on I am using the user <span class="monospaced">data</span> 
            and not using <span class="monospaced">root</span> anymore (or sudoing).
            <br>
            Go to the Spark download <a class="reference external" href="https://spark.apache.org/downloads.html" target="_blank">site</a> and
            get the file <span class="monospaced">spark-3.0.0-bin-hadoop3.2.tgz</span><sup><a href="#p2">[2]</a></sup>
        </p>

        <img src="images/spark_download_1.png" alt="Spark Download">

        <p>
            If you are intalling this on a remote server it may be best to <span class="monospaced">wget</span> it. 
            Just copy the URL from the download site and use it. Your mirror address may be different:
        </p>

        <img src="images/spark_download_2.png" alt="Spark Download">

        <pre><code class="shell">wget https://apache.dattatec.com/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz</code></pre>

        <p>Then uncompress and rename it (if you want to)</p>

        <pre><code class="shell">[data@sp3m ~]$ tar xf spark-3.0.0-bin-hadoop3.2.tgz
[data@sp3m ~]$ mv spark-3.0.0-bin-hadoop3.2.tgz spark</code></pre>

        <p>
            Edit <span class="monospaced">"~/.bash_profile"</span> file and add the following lines
        </p>

        <pre><code class="shell">export SPARK_HOME=/home/data/spark
export PATH=$SPARK_HOME/bin:$PATH</code></pre>

        <p>
            Then source the file to get the environment set.
        </p>

        <pre><code class="shell">. ~/.bash_profile</code></pre>

        <p>
            Finally lets try to start the Spark Shell
        </p>

        <pre><code class="shell">[data@sp3m ~]$ spark-shell 
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/data/spark/jars/spark-unsafe_2.12-3.0.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
20/06/23 06:48:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Spark context Web UI available at http://sp3m:4040
Spark context available as 'sc' (master = local[*], app id = local-1592909310324).
Spark session available as 'spark'.
Welcome to
       ____              __
      / __/__  ___ _____/ /__
     _\ \/ _ \/ _ `/ __/  '_/
    /___/ .__/\_,_/_/ /_/\_\   version 3.0.0
       /_/
            
Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 11.0.7)
Type in expressions to have them evaluated.
Type :help for more information.

scala></code></pre>

    <p>
        Yes! You may want to execute some code just to make sure this puppy can bark.
        <br>
        This is a simple example in Scala language. It doesn't matter if you don't know Scala, just copy the lines into
        the shell and verify you get the same results.
    </p>

    <pre><code class="scala">scala> val count = sc.parallelize(1 to 1000000).filter { _ => { val x = math.random; val y = math.random; x*x + y*y < 1 } }.count()
count: Long = 785440

scala> println(s"Pi is roughly ${4.0 * count / 1000000}")
Pi is roughly 3.14176

scala></code></pre>

    <p>
        And that's it. You have a funcional Spark node to start working with it.
    </p>

    </div>

    <div id="p1">
        [1] As long as it satisfies the minimun requirements. My advice is to use something with 8GB+ RAM to be sure. 
        I was able to run Spark version 2.4 on a machine with as low as 2GB RAM but had to make changes to memory settings here and there to
        make it work and even then had some problems. If you want to try and test the product with such a low amount of memory 
        is fine but you will need to roll up you sleves to make it work. You have been adverted.
    </div>
    <div id="p2">
        [2] You may be wondering why that file and not the other ones available and why the file we are downloading is related to Hadoop.
        As a matter of fact it does not make much difference unless you are using Hadoop. 
        If you are not, don't worry, any file you choose will work.
    </div>


</article>


